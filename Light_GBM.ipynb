{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f0cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, fbeta_score, log_loss, matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836b2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_csv('Final_Encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ab418",
   "metadata": {},
   "source": [
    "CLASS IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c667fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Count:\n",
      " 0    350352\n",
      "1    135179\n",
      "Name: flagged, dtype: int64\n",
      "\n",
      "Class Distribution Percentage:\n",
      " 0    72.158523\n",
      "1    27.841477\n",
      "Name: flagged, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_df is your DataFrame and 'flagged' is the column with class labels\n",
    "class_distribution = final_df['flagged'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "class_percentage = final_df['flagged'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the count and percentage of each class\n",
    "print(\"Class Distribution Count:\\n\", class_distribution)\n",
    "print(\"\\nClass Distribution Percentage:\\n\", class_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa05d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming final_df is your DataFrame and 'flagged' is the column with class labels\n",
    "class_distribution = final_df['flagged'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(class_distribution, labels=class_distribution.index, autopct='%1.1f%%', startangle=140, colors=plt.cm.viridis(np.linspace(0, 1, len(class_distribution))))\n",
    "plt.title('Class Distribution in flagged Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1ffe8",
   "metadata": {},
   "source": [
    "#### LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5469edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming final_df is your DataFrame and 'flagged' is the column with class labels\n",
    "selected_columns = ['ip_number', 'wallet_number_to', 'region', 'Adjusted Account Age','browser_environment', 'wallet_number_from', 'business_type_class',\n",
    "'city', 'trx_type', 'country','amount']\n",
    "X = final_df[selected_columns]\n",
    "y = final_df['flagged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55201b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END .....learning_rate=0.1, max_depth=-1, num_leaves=31; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END .....learning_rate=0.1, max_depth=-1, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END .....learning_rate=0.1, max_depth=-1, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END .....learning_rate=0.1, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END .....learning_rate=0.1, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END .....learning_rate=0.1, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.1, max_depth=-1, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.1, max_depth=-1, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ....learning_rate=0.1, max_depth=-1, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END .....learning_rate=0.1, max_depth=10, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END .....learning_rate=0.1, max_depth=10, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END .....learning_rate=0.1, max_depth=10, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END .....learning_rate=0.1, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END .....learning_rate=0.1, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END .....learning_rate=0.1, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ....learning_rate=0.1, max_depth=10, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ....learning_rate=0.1, max_depth=10, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ....learning_rate=0.1, max_depth=10, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END .....learning_rate=0.1, max_depth=20, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END .....learning_rate=0.1, max_depth=20, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END .....learning_rate=0.1, max_depth=20, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END .....learning_rate=0.1, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END .....learning_rate=0.1, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END .....learning_rate=0.1, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.1, max_depth=20, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.1, max_depth=20, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ....learning_rate=0.1, max_depth=20, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=-1, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=-1, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ....learning_rate=0.01, max_depth=-1, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....learning_rate=0.01, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ....learning_rate=0.01, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.01, max_depth=-1, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.01, max_depth=-1, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.01, max_depth=-1, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ....learning_rate=0.01, max_depth=10, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ....learning_rate=0.01, max_depth=10, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ....learning_rate=0.01, max_depth=10, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....learning_rate=0.01, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.01, max_depth=10, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.01, max_depth=10, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.01, max_depth=10, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ....learning_rate=0.01, max_depth=20, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ....learning_rate=0.01, max_depth=20, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ....learning_rate=0.01, max_depth=20, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ....learning_rate=0.01, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ....learning_rate=0.01, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.01, max_depth=20, num_leaves=100; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...learning_rate=0.01, max_depth=20, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.01, max_depth=20, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=-1, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=-1, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.001, max_depth=-1, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.001, max_depth=-1, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ..learning_rate=0.001, max_depth=-1, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ..learning_rate=0.001, max_depth=-1, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ..learning_rate=0.001, max_depth=-1, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ...learning_rate=0.001, max_depth=10, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ...learning_rate=0.001, max_depth=10, num_leaves=31; total time=   0.4s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ...learning_rate=0.001, max_depth=10, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.001, max_depth=10, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ..learning_rate=0.001, max_depth=10, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ..learning_rate=0.001, max_depth=10, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ..learning_rate=0.001, max_depth=10, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ...learning_rate=0.001, max_depth=20, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ...learning_rate=0.001, max_depth=20, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV] END ...learning_rate=0.001, max_depth=20, num_leaves=31; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ...learning_rate=0.001, max_depth=20, num_leaves=60; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ...learning_rate=0.001, max_depth=20, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2011\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ..learning_rate=0.001, max_depth=20, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72095, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2007\n",
      "[LightGBM] [Info] Number of data points in the train set: 258949, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278414 -> initscore=-0.952343\n",
      "[LightGBM] [Info] Start training from score -0.952343\n",
      "[CV] END ..learning_rate=0.001, max_depth=20, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 72096, number of negative: 186854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 258950, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278417 -> initscore=-0.952329\n",
      "[LightGBM] [Info] Start training from score -0.952329\n",
      "[CV] END ..learning_rate=0.001, max_depth=20, num_leaves=100; total time=   0.6s\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 108143, number of negative: 280281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2009\n",
      "[LightGBM] [Info] Number of data points in the train set: 388424, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278415 -> initscore=-0.952338\n",
      "[LightGBM] [Info] Start training from score -0.952338\n",
      "Best parameters found:  {'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 31}\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "y = final_df['flagged']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Define the model to tune\n",
    "model = lgb.LGBMClassifier(is_unbalance=True)\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 60, 100],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=2)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2690fee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jithi\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 108143, number of negative: 280281\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2009\n",
      "[LightGBM] [Info] Number of data points in the train set: 388424, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278415 -> initscore=-0.952338\n",
      "[LightGBM] [Info] Start training from score -0.952338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91     70071\n",
      "           1       0.74      0.81      0.78     27036\n",
      "\n",
      "    accuracy                           0.87     97107\n",
      "   macro avg       0.83      0.85      0.84     97107\n",
      "weighted avg       0.87      0.87      0.87     97107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_df is your DataFrame and 'flagged' is the column with class labels\n",
    "X = final_df[selected_columns]\n",
    "y = final_df['flagged']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Set LightGBM parameters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': True,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 100,\n",
    "    'max_bin': 255\n",
    "}\n",
    "\n",
    "# Create the LightGBM data containers\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# Train the model with the correct verbose_eval parameter\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100,\n",
    "    valid_sets=[train_data, test_data]\n",
    "    #verbose_eval=10  # Output the metric result every 10 iterations\n",
    ")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f71bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8699784773497277\n",
      "AUC: 0.9520106839977744\n",
      "AUCPR: 0.8957138449043459\n",
      "F0.5 Score: 0.7571069425643009\n",
      "F1 Score: 0.7764280908028474\n",
      "F2 Score: 0.7967612042272972\n",
      "GINI: 0.9040213679955489\n",
      "Log Loss: 0.3230838439726505\n",
      "MACROAUC: 0.9520106839977744\n",
      "MCC: 0.6862295970896841\n"
     ]
    }
   ],
   "source": [
    "# ACCURACY\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC:\", auc_score)\n",
    "\n",
    "# AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "aucpr = auc(recall, precision)\n",
    "print(\"AUCPR:\", aucpr)\n",
    "\n",
    "# F0.5 Score\n",
    "f05_score = fbeta_score(y_test, y_pred, beta=0.5)\n",
    "print(\"F0.5 Score:\", f05_score)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# F2 Score\n",
    "f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "print(\"F2 Score:\", f2_score)\n",
    "\n",
    "# GINI\n",
    "gini_score = 2 * roc_auc_score(y_test, y_pred_prob) - 1\n",
    "print(\"GINI:\", gini_score)\n",
    "\n",
    "# LOGLOSS\n",
    "logloss = log_loss(y_test, y_pred_prob)\n",
    "print(\"Log Loss:\", logloss)\n",
    "\n",
    "# MACROAUC (same as AUC if binary classification, different handling if multiclass)\n",
    "macro_auc = roc_auc_score(y_test, y_pred_prob, average='macro')\n",
    "print(\"MACROAUC:\", macro_auc)\n",
    "\n",
    "# MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93c0d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lgb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'lgb_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f'Model saved to {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355267ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
