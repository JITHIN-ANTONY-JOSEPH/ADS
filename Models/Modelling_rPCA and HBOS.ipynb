{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66e6956-35c0-4f08-a028-7dc1f5bac477",
   "metadata": {},
   "source": [
    "# 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5bba5-446b-49ac-a8b3-d24b3d6c6b7b",
   "metadata": {},
   "source": [
    "# 2.1 Robus PrincipalComponentAnalysis(rPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b63f5a4-08e9-4e95-a1da-a887b5ddfa74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pyod.models.hbos import HBOS\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e69da91-3e88-463c-aeb6-f302c3a14907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                            datetime64[ns]\n",
      "time                            datetime64[ns]\n",
      "trx_id                                  object\n",
      "trx_type                                object\n",
      "trx_status                              object\n",
      "category                                object\n",
      "business_type_class                     object\n",
      "wallet_number_from                     float64\n",
      "wallet_number_to                         int64\n",
      "amount                                 float64\n",
      "description                             object\n",
      "currency                                object\n",
      "invoice_details                         object\n",
      "ip                                      object\n",
      "browser_environment                     object\n",
      "amount_bin                              object\n",
      "datetime                        datetime64[ns]\n",
      "hour                                     int64\n",
      "day_of_week                              int64\n",
      "Wallet_to_change_frequency             float64\n",
      "IP Change Frequency                    float64\n",
      "First Transaction Date          datetime64[ns]\n",
      "Transaction Count                      float64\n",
      "Days Since First Transaction           float64\n",
      "Transaction Frequency                  float64\n",
      "Adjusted Account Age                   float64\n",
      "flagged                                   bool\n",
      "ip_number                                int64\n",
      "country                                 object\n",
      "city                                    object\n",
      "region                                  object\n",
      "lat                                    float64\n",
      "long                                   float64\n",
      "days_since_fixed_date                  float64\n",
      "days_since_first_transaction           float64\n",
      "principal_component_1                  float64\n",
      "principal_component_2                  float64\n",
      "is_outlier                               int64\n",
      "datetime_unix                            int64\n",
      "first_transaction_unix                   int64\n",
      "hbos_score                             float64\n",
      "predicted_label                          int64\n",
      "true_label                               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd250c72-2689-433f-985f-80e479d95a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/dg3f2g255y79fyvpc0gk48r80000gn/T/ipykernel_9695/2253479324.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_df['time'] = pd.to_datetime(final_df['time'])\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"Final_DF.csv\")\n",
    "\n",
    "final_df['date'] = pd.to_datetime(final_df['date'])\n",
    "final_df['time'] = pd.to_datetime(final_df['time'])\n",
    "\n",
    "numerical_features = final_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Handle NaN values, here simply use the mean to fill in the NaN values\n",
    "numerical_features.fillna(numerical_features.mean(), inplace=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b584ea-1a15-4e07-8855-d8b9b03b985d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exclude time-related columns\n",
    "features = final_df.drop(['date', 'time'], axis=1)\n",
    "\n",
    "# Get non-numeric columns\n",
    "non_numeric_cols = features.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Use label coding\n",
    "label_encoder = LabelEncoder()\n",
    "for col in non_numeric_cols:\n",
    "    features[col] = label_encoder.fit_transform(features[col])\n",
    "\n",
    "# Acquisition of features and target variables\n",
    "X = features.drop('flagged', axis=1)\n",
    "y = features['flagged']\n",
    "\n",
    "# Create a random forest classifier model\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# Access to feature significance\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed802047-b75f-4d1a-94e5-5384544041e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'datetime' and 'First Transaction Date'columns to datetime type\n",
    "final_df['datetime'] = pd.to_datetime(final_df['datetime'])\n",
    "final_df['First Transaction Date'] = pd.to_datetime(final_df['First Transaction Date'])\n",
    "\n",
    "# Convert datetime to Unix timestamps (in seconds)\n",
    "final_df['datetime_unix'] = final_df['datetime'].astype(int) // 10**9  # Convert to seconds\n",
    "final_df['first_transaction_unix'] = final_df['First Transaction Date'].astype(int) // 10**9  # Convert to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2764d8-c69a-4838-b6db-bf481b3ca7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(final_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17a325-4de2-4f50-bac8-a0a2432c3848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selection of features\n",
    "selected_features = ['amount', 'datetime_unix', 'Wallet_to_change_frequency', 'Transaction Count', 'first_transaction_unix', 'Days Since First Transaction',\n",
    "                     'Transaction Frequency','Adjusted Account Age','IP Change Frequency']\n",
    "\n",
    "# Extract selected features\n",
    "X = final_df[selected_features]\n",
    "\n",
    "# Define scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('pca', pca)\n",
    "])\n",
    "\n",
    "# Define parameter distribution for random search\n",
    "param_dist = {\n",
    "    'pca__n_components': np.arange(2, 10),  # Range of number of principal components\n",
    "    'pca__svd_solver': ['auto', 'full', 'arpack', 'randomized']  # Solver for SVD\n",
    "}\n",
    "\n",
    "# Perform random search\n",
    "random_search = RandomizedSearchCV(pipeline, param_dist, cv=5, n_iter=10, random_state=42)\n",
    "random_search.fit(X)\n",
    "\n",
    "# Output best parameters\n",
    "print(\"Best parameters found by random search:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f9b5a-f73a-47f2-b0fc-e673b349c706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selection of features\n",
    "selected_features = ['amount', 'datetime_unix', 'Wallet_to_change_frequency', 'Transaction Count', 'first_transaction_unix', 'Days Since First Transaction',\n",
    "                     'Transaction Frequency','Adjusted Account Age','IP Change Frequency']\n",
    "\n",
    "# Extract selected features\n",
    "X = final_df[selected_features]\n",
    "\n",
    "# Define scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply Robust PCA modeling with best hyperparameters\n",
    "rpca = PCA(n_components=6, svd_solver='full')\n",
    "principal_components = rpca.fit_transform(X)\n",
    "\n",
    "# Calculate the squared reconstruction error\n",
    "reconstruction_errors = np.square(X - rpca.inverse_transform(principal_components)).sum(axis=1)\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = np.percentile(reconstruction_errors, 95)  # for example, 95th percentile\n",
    "\n",
    "# Label data points as outliers if their reconstruction error is above the threshold\n",
    "is_outlier = reconstruction_errors > threshold\n",
    "\n",
    "# Output the counts of outliers and inliers\n",
    "num_outliers = np.sum(is_outlier)\n",
    "num_inliers = X.shape[0] - num_outliers\n",
    "print(\"Number of outliers:\", num_outliers)\n",
    "print(\"Number of inliers:\", num_inliers)\n",
    "\n",
    "# Generate classification report\n",
    "y_true = final_df['flagged']\n",
    "y_pred = is_outlier.astype(int)\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c04b6-3f87-41c7-a26e-fb9f6fe57e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting relationships between principal components\n",
    "plt.scatter(final_df['principal_component_1'], final_df['principal_component_2'], c=final_df['is_outlier'], cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Outlier Detection')\n",
    "plt.colorbar(label='Flagged as Outlier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8977b-9619-458c-8610-af32a35ecd15",
   "metadata": {},
   "source": [
    "# 2.2 HBOS（Historical Based Outlier Score）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be9259-a2f4-42d5-8e58-79a29f94092c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the features used by the HBOS model\n",
    "features = ['amount', 'datetime_unix', 'Wallet_to_change_frequency', 'Transaction Count', 'first_transaction_unix', 'Days Since First Transaction',\n",
    "            'Transaction Frequency','Adjusted Account Age','IP Change Frequency']\n",
    "\n",
    "# Initialize HBOS model with specified contamination factors\n",
    "hbos_model = HBOS(contamination=0.05)  \n",
    "\n",
    "# Standardized selected features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(final_df[features])\n",
    "\n",
    "# Adaptation of HBOS models with standardized data\n",
    "hbos_model.fit(scaled_data)\n",
    "\n",
    "# Get the model's decision score (higher values indicate more anomalous)\n",
    "final_df['hbos_score'] = hbos_model.decision_function(scaled_data)\n",
    "\n",
    "# Print data frame with HBOS scores\n",
    "print(final_df[['hbos_score'] + features])\n",
    "\n",
    "# Determine thresholds for flagging outliers\n",
    "threshold = final_df['hbos_score'].quantile(0.95)\n",
    "\n",
    "# Create a new column that marks scores above the threshold as exceptions\n",
    "final_df['predicted_label'] = (final_df['hbos_score'] > threshold).astype('int')\n",
    "\n",
    "# The real label column 'flagged' should already exist in final_df\n",
    "# Convert them to the same format as the predicted labels\n",
    "final_df['true_label'] = final_df['flagged'].astype('int')\n",
    "\n",
    "report = classification_report(final_df['true_label'], final_df['predicted_label'], target_names=['False', 'True'])\n",
    "print(report)\n",
    "\n",
    "# Filter outliers and non-outliers based on thresholds\n",
    "outliers = final_df[final_df['hbos_score'] > threshold]\n",
    "inliers = final_df[final_df['hbos_score'] <= threshold]\n",
    "\n",
    "# of outliers and non-outliers counted\n",
    "num_outliers = outliers.shape[0]\n",
    "num_inliers = inliers.shape[0]\n",
    "\n",
    "# Count the number of each class\n",
    "class_counts = final_df['predicted_label'].value_counts()\n",
    "\n",
    "# Output the counts of each class\n",
    "print(\"Number of outliers:\", class_counts[1])\n",
    "print(\"Number of inliers:\", class_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab42d9-9c2d-4b3c-8fec-1bbb46c5ad8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score\n",
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "# Define the features used by the HBOS model\n",
    "features = ['amount', 'datetime_unix', 'Wallet_to_change_frequency', 'Transaction Count', 'first_transaction_unix', 'Days Since First Transaction',\n",
    "            'Transaction Frequency','Adjusted Account Age','IP Change Frequency']\n",
    "\n",
    "# Initialize HBOS model\n",
    "hbos_model = HBOS()\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'contamination': [0.01, 0.05, 0.1, 0.15]  # Adjust contamination factor\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(hbos_model, param_grid, cv=5, scoring='average_precision')\n",
    "grid_search.fit(final_df[features])\n",
    "\n",
    "# Output best parameters\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49603cbd-4ece-43b3-92bc-729a77812671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the features used by the HBOS model\n",
    "features = ['amount', 'datetime_unix', 'Wallet_to_change_frequency', 'Transaction Count', 'first_transaction_unix', 'Days Since First Transaction',\n",
    "            'Transaction Frequency','Adjusted Account Age','IP Change Frequency']\n",
    "\n",
    "# Initialize HBOS model with best parameters\n",
    "hbos_model = HBOS(contamination=0.01)\n",
    "\n",
    "# Standardized selected features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(final_df[features])\n",
    "\n",
    "# Fit the HBOS model to the standardized data\n",
    "hbos_model.fit(scaled_data)\n",
    "\n",
    "# Get the model's decision score (higher values indicate more anomalous)\n",
    "final_df['hbos_score'] = hbos_model.decision_function(scaled_data)\n",
    "\n",
    "# Print data frame with HBOS scores\n",
    "print(final_df[['hbos_score'] + features])\n",
    "\n",
    "# Determine thresholds for flagging outliers\n",
    "threshold = final_df['hbos_score'].quantile(0.95)\n",
    "\n",
    "# Create a new column that marks scores above the threshold as exceptions\n",
    "final_df['predicted_label'] = (final_df['hbos_score'] > threshold).astype('int')\n",
    "\n",
    "# The real label column 'flagged' should already exist in final_df\n",
    "# Convert them to the same format as the predicted labels\n",
    "final_df['true_label'] = final_df['flagged'].astype('int')\n",
    "\n",
    "# Generate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(final_df['true_label'], final_df['predicted_label'], target_names=['False', 'True'])\n",
    "print(report)\n",
    "\n",
    "# Filter outliers and non-outliers based on thresholds\n",
    "outliers = final_df[final_df['hbos_score'] > threshold]\n",
    "inliers = final_df[final_df['hbos_score'] <= threshold]\n",
    "\n",
    "# Count the number of each class\n",
    "class_counts = final_df['predicted_label'].value_counts()\n",
    "\n",
    "# Output the counts of each class\n",
    "print(\"Number of outliers:\", class_counts[1])\n",
    "print(\"Number of inliers:\", class_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd53e0-9cf3-44f6-a9ee-543a998af28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting histograms of anomaly scores\n",
    "plt.hist(final_df['hbos_score'], bins=20, edgecolor='black')\n",
    "plt.axvline(x=threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.xlabel('HBOS Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of HBOS Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
